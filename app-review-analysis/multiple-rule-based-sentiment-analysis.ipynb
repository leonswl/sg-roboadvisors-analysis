{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1.2 - Rule Based Sentiment Analysis\n",
    "\n",
    "Using 3 types of lexicon based approach to conduct sentiment analysis on app reviews\n",
    "- TextBlob\n",
    "- VADER\n",
    "- SentiWordNet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import rule based sentiment analysis libaries\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/a844133yara.com/.pyenv/versions/3.9.5/envs/python_playground/lib/python3.9/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# import file\n",
    "app_reviews = pd.read_csv('app_reviews.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data Preprocessing\n",
    "Data preprocessing steps:\n",
    "\n",
    "1. Cleaning the text\n",
    "2. Tokenization\n",
    "3. Enrichment – POS tagging\n",
    "4. Stopwords removal\n",
    "5. Obtaining the stem words"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Cleaning the Text\n",
    "\n",
    "Remove the special characters, numbers from the review text using regex"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Tokenisation\n",
    "\n",
    "Using nltk tokenize function word_tokenize() to perform word-level tokenization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Enrichment – POS tagging\n",
    "\n",
    "Using the nltk pos_tag function to perform Parts of Speech (POS) tagging - converting each token into a tuple having the form (word, tag). POS tagging essential to preserve the context of the word and is essential for Lemmatization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Stopwords removal\n",
    "Stopwords in English are words that carry very little useful information. We need to remove them as part of text preprocessing. nltk has a list of stopwords of every language. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Obtaining the stem words\n",
    "A stem is a part of a word responsible for its lexical meaning. The two popular techniques of obtaining the root/stem words are Stemming and Lemmatization.\n",
    "\n",
    "The key difference is Stemming often gives some meaningless root words as it simply chops off some characters in the end. Lemmatization gives meaningful root words, however, it requires POS tags of the words."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('python_playground': pyenv)"
  },
  "interpreter": {
   "hash": "a6d1b274f901ed7a2522d7326b4d4fc301d947b33c5f55b995b8ab621df4372a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}